\BOOKMARK [0][-]{chapter.1}{Problem 1: Tensorflow Softmax \(25 pts\)}{}% 1
\BOOKMARK [1][-]{section.1.1}{\(a\) \040Softmax in Tensorflow \(5 pts\)}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{\(b\) \040Cross-Entropy Loss in Tensorflow \(5 pts\)}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.3}{\(c\) \040Placeholders and Feed Dictionaries \(5 pts\)}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.4}{\(d\) \040Add Softmax and Add CE Loss \(5 pts\)}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.5}{\(e\) \040Add Training Optimizer \205 Gradient Descent \(5 pts\)}{chapter.1}% 6
\BOOKMARK [0][-]{chapter.2}{Problem 2: Neural Transition-Based Dependency Parsing \(50 pts\)}{}% 7
\BOOKMARK [1][-]{section.2.1}{\(a\) \040Parsing Steps by Hand \(6 pts\)}{chapter.2}% 8
\BOOKMARK [1][-]{section.2.2}{\(b\) \040Number of Steps to Parse \(2 pts\)}{chapter.2}% 9
\BOOKMARK [1][-]{section.2.3}{\(c\) \040Partial Parse Coding \(6 pts\)}{chapter.2}% 10
\BOOKMARK [1][-]{section.2.4}{\(d\) \040Minibatch Parsing \(6 pts\)}{chapter.2}% 11
\BOOKMARK [1][-]{section.2.5}{\(N/A\) \040Description \(for actual problem see Subproblem 2.6\)}{chapter.2}% 12
\BOOKMARK [1][-]{section.2.6}{\(e\) \040Xavier Initialization \(4 pts\)}{chapter.2}% 13
\BOOKMARK [1][-]{section.2.7}{\(f\) \040Dropout Regularization \(2 pts\)}{chapter.2}% 14
\BOOKMARK [1][-]{section.2.8}{\(g\) \040Adam Optimizer \(4 pts\)}{chapter.2}% 15
\BOOKMARK [1][-]{section.2.9}{\(h\) \040Neural Dependency Parser \(20 pts\)}{chapter.2}% 16
\BOOKMARK [0][-]{chapter.3}{Problem 3: Recurrent Neural Networks: Language Modeling \(25 pts\)}{}% 17
\BOOKMARK [1][-]{section.3.1}{\(a\) \040Perplexity and Cross-Entropy Loss \(5 pts\)}{chapter.3}% 18
\BOOKMARK [1][-]{section.3.2}{\(b\) \040Gradients w.r.t. the Loss \(8 pts\)}{chapter.3}% 19
\BOOKMARK [1][-]{section.3.3}{\(c\) \040Backpropagation Through Time \(BPTT\) \(8 pts\)}{chapter.3}% 20
\BOOKMARK [1][-]{section.3.4}{\(d\) \040Computational Complexity \(4 pts\)}{chapter.3}% 21
